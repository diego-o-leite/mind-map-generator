{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Imports the libraries and functions that will be necessary to create mind maps from PDFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This module handles AI-powered mind map generation using the Gemini API.\n",
    "It includes utilities for retrying API calls, environment variable management,\n",
    "and Jupyter notebook display enhancements.\n",
    "\"\"\"\n",
    "\n",
    "# Standard library imports\n",
    "import os\n",
    "import time\n",
    "import datetime\n",
    "import subprocess\n",
    "import threading\n",
    "import itertools\n",
    "\n",
    "# Third-party imports\n",
    "from tenacity import retry, stop_after_attempt, wait_exponential\n",
    "from dotenv import load_dotenv\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Jupyter-specific imports\n",
    "from IPython.display import Image, display, clear_output\n",
    "from ipywidgets import widgets, IntProgress, HBox, Label, Button, Layout\n",
    "\n",
    "# Load environment variables from 'keys.env' file\n",
    "# This file should contain the GOOGLE_API_KEY\n",
    "load_dotenv(\"keys.env\")\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')\n",
    "\n",
    "# Configure the Gemini model using the API key\n",
    "# Ensure the API key is valid and has necessary permissions\n",
    "genai.configure(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "# Initialize the Gemini model\n",
    "# Using 'gemini-1.5-flash' for faster processing\n",
    "model = genai.GenerativeModel(model_name=\"gemini-1.5-flash\")\n",
    "\n",
    "# Define the prompt_text for mind map generation\n",
    "# This multi-line string contains instructions for the AI model\n",
    "prompt_text = '''\n",
    "Please create a mind map of this PDF in .puml format with topics and subtopics to be used in plantuml, without indentations.\n",
    "Ensure that the .puml file contains no more than 90 lines. You are encouraged to fill 60-80 lines.\n",
    "Maintain the language of the PDF.\n",
    "The first level should start with '* '. The second level should start with '** ', and so on.\n",
    "Do not use '-' at the beginning of each topic.\n",
    "The map should have at least 4 levels.\n",
    "At the first level, 1 to 10 words are allowed. Try to use this maximum word limit I am giving you to explore concepts.\n",
    "At the second level, 1 to 10 words are allowed. Try to use this maximum word limit I am giving you to explore concepts.\n",
    "At the third level, 1 to 20 words are allowed. You are encouraged to form phrases in this level.\n",
    "At the fourth level, 1 to 20 words are allowed. You are encouraged to form phrases in this level.\n",
    "Do not include final considerations, complementary materials, bibliographic references, or other topics that do not explicitly explain concepts.\n",
    "'''\n",
    "\n",
    "def check_files_in_genai_cloud():\n",
    "    \"\"\"\n",
    "    Check if there are any files present in the Gemini AI cloud storage.\n",
    "\n",
    "    This function uses the Gemini AI API to list files in the cloud storage\n",
    "    and returns True if at least one file is present, False otherwise.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if there are files in the cloud storage, False if it's empty.\n",
    "\n",
    "    Raises:\n",
    "        APIError: If there's an error in communicating with the Gemini AI API.\n",
    "\n",
    "    Example:\n",
    "        >>> has_files = check_files_in_genai_cloud()\n",
    "        >>> print(has_files)\n",
    "        True\n",
    "    \"\"\"\n",
    "    return any(genai.list_files())\n",
    "\n",
    "def remove_files_from_cloud():\n",
    "    \"\"\"\n",
    "    Remove all files from the Gemini AI cloud storage.\n",
    "\n",
    "    This function iterates through all files in the Gemini AI cloud storage\n",
    "    and attempts to delete each one. It provides feedback on the success or\n",
    "    failure of each deletion operation.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "\n",
    "    Raises:\n",
    "        APIError: If there's an error in communicating with the Gemini AI API.\n",
    "\n",
    "    Side Effects:\n",
    "        - Deletes files from the Gemini AI cloud storage.\n",
    "        - Prints status messages to the console for each file deletion attempt.\n",
    "\n",
    "    Example:\n",
    "        >>> remove_files_from_cloud()\n",
    "        The file \"document1.pdf\" was removed from the cloud.\n",
    "        The file \"image1.jpg\" was removed from the cloud.\n",
    "        Error removing file \"locked_file.txt\": Permission denied\n",
    "    \"\"\"\n",
    "    for file in genai.list_files():\n",
    "        try:\n",
    "            genai.delete_file(file.name)\n",
    "            print(f\"The file {file.display_name} was removed from the cloud.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error removing file {file.display_name}: {e}\")\n",
    "\n",
    "def upload_files_to_cloud(inputs_path):\n",
    "    \"\"\"\n",
    "    Upload PDF files from a specified directory to the Gemini AI cloud storage.\n",
    "\n",
    "    This function scans the given directory for PDF files, sorts them by creation time,\n",
    "    and uploads them to the Gemini AI cloud storage. It provides feedback on the success\n",
    "    or failure of each upload operation.\n",
    "\n",
    "    Args:\n",
    "        inputs_path (str): The path to the directory containing PDF files to upload.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of successfully uploaded file objects from the Gemini AI API.\n",
    "\n",
    "    Raises:\n",
    "        APIError: If there's an error in communicating with the Gemini AI API.\n",
    "\n",
    "    Side Effects:\n",
    "        - Uploads files to the Gemini AI cloud storage.\n",
    "        - Prints status messages to the console for each file upload attempt.\n",
    "        - Introduces a 1-second delay between uploads to avoid overwhelming the API.\n",
    "\n",
    "    Example:\n",
    "        >>> uploaded = upload_files_to_cloud(\"/path/to/pdf/directory\")\n",
    "        Uploaded file 'document1.pdf' as: gemini://abc123\n",
    "        Uploaded file 'document2.pdf' as: gemini://def456\n",
    "        Error uploading file large_file.pdf: File size exceeds limit\n",
    "        >>> print(len(uploaded))\n",
    "        2\n",
    "    \"\"\"\n",
    "    if not os.path.exists(inputs_path):\n",
    "        print(f\"Directory {inputs_path} does not exist.\")\n",
    "        return []\n",
    "\n",
    "    files = [os.path.join(inputs_path, pdf) for pdf in os.listdir(inputs_path) if pdf.endswith('.pdf')]\n",
    "    files.sort(key=os.path.getctime)\n",
    "    \n",
    "    uploaded_files = []\n",
    "    for path in files:\n",
    "        pdf_name = os.path.basename(path)\n",
    "        try:\n",
    "            file = genai.upload_file(path=path, display_name=pdf_name)\n",
    "            print(f\"Uploaded file '{file.display_name}' as: {file.uri}\")\n",
    "            uploaded_files.append(file)\n",
    "            time.sleep(1)\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading file {pdf_name}: {e}\")\n",
    "    \n",
    "    return uploaded_files\n",
    "\n",
    "# Execute the prompt using the Gemini API, retrieve the response and ensure the response will be in puml mindmap format\n",
    "def run_API(file, prompt):\n",
    "    \"\"\"\n",
    "    Execute a prompt using the Gemini API and return a PUML mindmap.\n",
    "\n",
    "    This function sends the given prompt to the Gemini API, retrieves the response,\n",
    "    and ensures that the response is formatted as a PUML mindmap.\n",
    "\n",
    "    Args:\n",
    "        prompt (str): The prompt to send to the Gemini API.\n",
    "\n",
    "    Returns:\n",
    "        str: A PUML-formatted mindmap string.\n",
    "\n",
    "    Raises:\n",
    "        ValueError: If the response is not in the correct PUML mindmap format.\n",
    "    \"\"\"\n",
    "    response = model.generate_content([file, prompt])\n",
    "    lines = response.text.split('\\n')\n",
    "    \n",
    "    # Ensure that the start is '@startmindmap'\n",
    "    if not lines[0] == '@startmindmap':\n",
    "        lines.insert(0, '@startmindmap')\n",
    "    \n",
    "    # Ensure that the end is '@endmindmap'\n",
    "    if not lines[-1] == '@endmindmap':\n",
    "        lines.append('@endmindmap')\n",
    "    \n",
    "    # Filter only lines that start with '*', except the first and last\n",
    "    filtered_lines = ['@startmindmap'] + [line for line in lines[1:-1] if line.startswith('*')] + ['@endmindmap']\n",
    "    \n",
    "    str_puml = '\\n'.join(filtered_lines)\n",
    "    return str_puml, filtered_lines\n",
    "\n",
    "# Check if the created map has at least one level 4 subtopic\n",
    "def check_criteria(lines):\n",
    "    \"\"\"\n",
    "    Check if the generated mind map has at least one level 4 subtopic.\n",
    "\n",
    "    This function examines a list of strings representing a mind map structure\n",
    "    and verifies if there's at least one line starting with four asterisks,\n",
    "    which indicates a level 4 subtopic in the PUML mind map format.\n",
    "\n",
    "    Args:\n",
    "        lines (list of str): A list of strings representing the lines of a PUML mind map.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if at least one level 4 subtopic is found, False otherwise.\n",
    "\n",
    "    Example:\n",
    "        >>> mind_map_lines = [\n",
    "        ...     \"@startmindmap\",\n",
    "        ...     \"* Root\",\n",
    "        ...     \"** Level 2\",\n",
    "        ...     \"*** Level 3\",\n",
    "        ...     \"**** Level 4\",\n",
    "        ...     \"@endmindmap\"\n",
    "        ... ]\n",
    "        >>> result = check_criteria(mind_map_lines)\n",
    "        >>> print(result)\n",
    "        True\n",
    "\n",
    "        >>> simple_map = [\n",
    "        ...     \"@startmindmap\",\n",
    "        ...     \"* Root\",\n",
    "        ...     \"** Level 2\",\n",
    "        ...     \"*** Level 3\",\n",
    "        ...     \"@endmindmap\"\n",
    "        ... ]\n",
    "        >>> result = check_criteria(simple_map)\n",
    "        >>> print(result)\n",
    "        False\n",
    "    \"\"\"\n",
    "    return any(line.startswith(\"**** \") for line in lines)\n",
    "\n",
    "# Retry file processing up to 5 times with exponential backoff, ensuring generated PUML meets criteria\n",
    "@retry(stop=stop_after_attempt(5), wait=wait_exponential(multiplier=1, min=4, max=10))\n",
    "def process_file_with_retry(file, prompt):\n",
    "    str_puml, lines = run_API(file, prompt)\n",
    "    if not check_criteria(lines):\n",
    "        raise ValueError(\"Generated PUML does not meet criteria\")\n",
    "    return str_puml, lines\n",
    "\n",
    "def generate_mind_map(str_puml, file_name):\n",
    "    timestamp = datetime.datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    output_dir = \"outputs\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    path_puml = os.path.join(output_dir, f\"{timestamp}_mapa_mental_{os.path.splitext(file_name)[0]}.puml\")\n",
    "    path_png = path_puml[:-4] + \"png\"\n",
    "    \n",
    "    with open(path_puml, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(str_puml)\n",
    "    \n",
    "    plantuml_jar_path = \"plantuml_jar\\\\plantuml-1.2024.7.jar\"\n",
    "    if run_plantuml(path_puml, plantuml_jar_path):\n",
    "        if os.path.exists(path_png):\n",
    "            display(Image(path_png))\n",
    "        else:\n",
    "            print(\"Image not found. Check if PlantUML correctly converted the .puml file to .png.\")\n",
    "    else:\n",
    "        print(\"Failed to generate the image.\")\n",
    "\n",
    "def run_plantuml(path_puml, plantuml_jar_path):\n",
    "    try:\n",
    "        result = subprocess.run(\n",
    "            [\"java\", \"-Dfile.encoding=UTF-8\", \"-jar\", plantuml_jar_path, path_puml],\n",
    "            check=True,\n",
    "            capture_output=True,\n",
    "            text=True\n",
    "        )\n",
    "        print(\"Image generated successfully!\")\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error generating image: {e}\")\n",
    "        print(f\"STDOUT: {e.stdout}\")\n",
    "        print(f\"STDERR: {e.stderr}\")\n",
    "        return False\n",
    "\n",
    "def spinning_indicator():\n",
    "    spinner = itertools.cycle(['-', '/', '|', '\\\\'])\n",
    "    while True:\n",
    "        yield next(spinner)\n",
    "\n",
    "def update_spinner_controlled(spinner_label, running_event):\n",
    "    for c in spinning_indicator():\n",
    "        if not running_event.is_set():\n",
    "            break\n",
    "        spinner_label.value = c\n",
    "        time.sleep(0.1)\n",
    "    spinner_label.value = ''  # Limpa o spinner quando a thread termina\n",
    "\n",
    "def process_files(files):\n",
    "    progress = IntProgress(min=0, max=len(files), description='Files:')\n",
    "    spinner_label = Label(value='-')\n",
    "    status_label = Label(value='Processing...')\n",
    "    \n",
    "    display(HBox([progress, spinner_label, status_label]))\n",
    "    \n",
    "    # Variável para controlar a execução da thread do spinner\n",
    "    spinner_running = threading.Event()\n",
    "    spinner_running.set()  # Inicialmente, definimos como True\n",
    "\n",
    "    spinner_thread = threading.Thread(target=update_spinner_controlled, args=(spinner_label, spinner_running))\n",
    "    spinner_thread.daemon = True\n",
    "    spinner_thread.start()\n",
    "\n",
    "    try:\n",
    "        total_files = len(files)\n",
    "        for i, file in enumerate(files):\n",
    "            status_label.value = f'Processing {file.display_name}...'\n",
    "            \n",
    "            try:\n",
    "                str_puml, _ = process_file_with_retry(file, prompt_text)\n",
    "                generate_mind_map(str_puml, file.display_name)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to process {file.display_name}: {e}\")\n",
    "            finally:\n",
    "                progress.value = i + 1\n",
    "                if i < total_files - 1:  # Se não for o último arquivo\n",
    "                    print(\"10-second suspension initiated...\")\n",
    "                    for remaining in range(10, 0, -1):\n",
    "                        status_label.value = f\"10-second suspension initiated... {remaining} seconds remaining\"\n",
    "                        time.sleep(1)\n",
    "                else:\n",
    "                    print(\"All files processed.\")\n",
    "        \n",
    "        status_label.value = 'Finished!'\n",
    "    finally:\n",
    "        spinner_running.clear()  # Sinaliza para a thread do spinner parar\n",
    "        spinner_thread.join(timeout=1)  # Espera a thread do spinner terminar (com timeout)\n",
    "\n",
    "    print(\"Script finished! All files in the 'pdf' folder have been scanned to generate mind maps.\")\n",
    "\n",
    "def run_workflow(upload_new_files=True):\n",
    "    global sorted_files\n",
    "    \n",
    "    if upload_new_files:\n",
    "        if check_files_in_genai_cloud():\n",
    "            remove_files_from_cloud()\n",
    "        \n",
    "        uploaded_files = upload_files_to_cloud(inputs_path)\n",
    "        sorted_files = sorted(uploaded_files, key=lambda file: file.create_time)\n",
    "        \n",
    "        print(\"Uploaded files:\")\n",
    "        for file in sorted_files:\n",
    "            print(f\"{file.display_name} - {file.create_time}\")\n",
    "    else:\n",
    "        if not check_files_in_genai_cloud():\n",
    "            print(\"No files in the cloud. Please upload new files.\")\n",
    "            return\n",
    "        \n",
    "        sorted_files = sorted(list(genai.list_files()), key=lambda file: file.create_time)\n",
    "        print(\"Using existing files in the cloud:\")\n",
    "        for file in sorted_files:\n",
    "            print(f\"{file.display_name} - {file.create_time}\")\n",
    "    \n",
    "    print(\"Starting map generation...\")\n",
    "    process_files(sorted_files)\n",
    "\n",
    "# Creating widgets for user interaction\n",
    "upload_button = widgets.Button(description=\"Upload and Process\", layout=widgets.Layout(width='150px'))\n",
    "reprocess_button = widgets.Button(description=\"Reprocess Uploaded Files\", layout=widgets.Layout(width='200px'))\n",
    "\n",
    "upload_button.on_click(lambda _: run_workflow(True))\n",
    "reprocess_button.on_click(lambda _: run_workflow(False))\n",
    "\n",
    "# Displaying the buttons\n",
    "display(widgets.HBox([upload_button, reprocess_button]))\n",
    "\n",
    "# Defining the inputs directory\n",
    "inputs_path = \"inputs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(run_API.__doc__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
